{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "from scitbx import *\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fluxnet\n",
    "timestamp_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "\n",
    "out_folder = r\"C:\\workspace\\repositories\\fluxlib\\data\\comparison\"\n",
    "out_full_folder = r\"C:\\workspace\\repositories\\fluxlib\\data\\comparison_full\"\n",
    "\n",
    "mds_flder = r\"C:\\workspace\\repositories\\fluxlib\\data\\mds_out\"\n",
    "flx4mds_flder = r\"C:\\workspace\\repositories\\fluxlib\\data\\fluxnet4mds_csv\"\n",
    "vld_flder = r\"C:\\workspace\\repositories\\fluxlib\\data\\fluxnet4mds_csv_validate\"\n",
    "apl_flder = r\"C:\\workspace\\repositories\\fluxlib\\data\\fluxnet4rfr_apply\"\n",
    "\n",
    "mds_paths = list(Path(mds_flder).glob(r\"*.txt\"))\n",
    "x_paths = list(Path(flx4mds_flder).glob(r\"*.csv\"))\n",
    "x_names = [p.stem.split(\"_\")[0] for p in x_paths]\n",
    "\n",
    "vld_paths = list(Path(vld_flder).glob(r\"*.csv\"))\n",
    "apl_paths = list(Path(apl_flder).glob(r\"*.csv\"))\n",
    "\n",
    "for pm in mds_paths:\n",
    "    name = pm.stem.split(\"_\")[0]\n",
    "    idx = x_names.index(name)\n",
    "    df_x = pd.read_csv(x_paths[idx], index_col = 0)\n",
    "    df_x.index = df_x.index.map(\n",
    "        lambda x: datetime.strptime(str(x), timestamp_format)\n",
    "    )\n",
    "    mds = pd.read_csv(pm, delimiter = \"\\t\", skiprows = [1]).set_index(df_x.index)[[\"NEE_f\"]]\n",
    "    mds = mds.replace(-9999, np.nan)\n",
    "    \n",
    "    assert vld_paths[idx].stem.split(\"_\")[0] == name == apl_paths[idx].stem.split(\"_\")[0]\n",
    "    rfr = pd.read_csv(apl_paths[idx]).set_index(df_x.index)[[\"truth\", \"estimates\"]]\n",
    "    res = pd.concat([rfr, mds], axis = 1)\n",
    "    res.to_csv(Path(out_full_folder).joinpath(f\"{pm.stem[0: -4]}.csv\"))\n",
    "    \n",
    "    vld = pd.read_csv(vld_paths[idx], index_col = 0)\n",
    "    vld.index = vld.index.map(\n",
    "        lambda x: datetime.strptime(str(x), timestamp_format)\n",
    "    )\n",
    "    # print(vld)\n",
    "    extract_vld = res.loc[vld.index]\n",
    "    x = extract_vld.dropna()[\"truth\"]\n",
    "    y1 = extract_vld.dropna()[\"estimates\"]\n",
    "    y2 = extract_vld.dropna()[\"NEE_f\"]\n",
    "    #--------------------------------------------\n",
    "    _, _, r_value, _, _ = stats.linregress(x, y1)\n",
    "    r2_1 = r_value**2\n",
    "    mse = mean_squared_error(x, y1)\n",
    "    rmse_1 = np.sqrt(mse)   \n",
    "    # -------------------------------------------\n",
    "    _, _, r_value, _, _ = stats.linregress(x, y2)\n",
    "    r2_2 = r_value**2\n",
    "    mse = mean_squared_error(x, y2)\n",
    "    rmse_2 = np.sqrt(mse)  \n",
    "    # -------------------------------------------\n",
    "    \n",
    "    extract_vld.to_csv(Path(out_folder).joinpath(f\"{pm.stem[0: -4]}.csv\"))\n",
    "    print(f\"{name}, RFR: {np.round(r2_1, 2)}, {np.round(rmse_1, 2)}; MDS: {np.round(r2_2, 2)}, {np.round(rmse_2, 2)}\")\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebungan, RFR: 0.78, 6.69; MDS: 0.75, 7.12\n"
     ]
    }
   ],
   "source": [
    "# for malaysia\n",
    "timestamp_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "\n",
    "out_folder = r\"C:\\workspace\\repositories\\fluxlib\\data\\malaysia_synthetic_scenario\\comparison\"\n",
    "create_all_parents(out_folder)\n",
    "out_full_folder = r\"C:\\workspace\\repositories\\fluxlib\\data\\malaysia_synthetic_scenario\\comparison_full\"\n",
    "create_all_parents(out_full_folder)\n",
    "\n",
    "mds_flder = r\"C:\\workspace\\repositories\\fluxlib\\data\\malaysia_synthetic_scenario\\mds_out\"\n",
    "# flx4mds_flder = r\"C:\\workspace\\repositories\\fluxlib\\data\\malaysia_synthetic_scenario\\fluxnet4mds_csv\"\n",
    "vld_flder = r\"C:\\workspace\\repositories\\fluxlib\\data\\malaysia_synthetic_scenario\\malaysia4mds_csv_validate\"\n",
    "apl_flder = r\"C:\\workspace\\repositories\\fluxlib\\data\\malaysia_synthetic_scenario\\malaysia4rfr_apply\"\n",
    "\n",
    "mds_path = list(Path(mds_flder).glob(r\"*.txt\"))[0]\n",
    "name = mds_path.stem.split(\"_\")[0]\n",
    "\n",
    "vld_path = list(Path(vld_flder).glob(r\"*.csv\"))[0]\n",
    "apl_path = list(Path(apl_flder).glob(r\"*.csv\"))[0]\n",
    "\n",
    "df_app = pd.read_csv(apl_path, index_col = 0)\n",
    "df_app.index = df_app.index.map(\n",
    "    lambda x: datetime.strptime(str(x), timestamp_format)\n",
    ")\n",
    "mds = pd.read_csv(mds_path, delimiter = \"\\t\", skiprows = [1]).set_index(df_app.index)[[\"NEE_f\"]]\n",
    "mds = mds.replace(-9999, np.nan)\n",
    "\n",
    "rfr = df_app[[\"truth\", \"estimates\"]]\n",
    "res = pd.concat([rfr, mds], axis = 1)\n",
    "res.to_csv(Path(out_full_folder).joinpath(f\"{pm.stem[0: -4]}.csv\"))\n",
    "\n",
    "vld = pd.read_csv(vld_path, index_col = 0)\n",
    "vld.index = vld.index.map(\n",
    "    lambda x: datetime.strptime(str(x), timestamp_format)\n",
    ")\n",
    "# print(vld)\n",
    "extract_vld = res.loc[vld.index]\n",
    "x = extract_vld.dropna()[\"truth\"]\n",
    "y1 = extract_vld.dropna()[\"estimates\"]\n",
    "y2 = extract_vld.dropna()[\"NEE_f\"]\n",
    "extract_vld.to_csv(Path(out_folder).joinpath(f\"{pm.stem[0: -4]}.csv\"))\n",
    "#--------------------------------------------\n",
    "_, _, r_value, _, _ = stats.linregress(x, y1)\n",
    "r2_1 = r_value**2\n",
    "mse = mean_squared_error(x, y1)\n",
    "rmse_1 = np.sqrt(mse)   \n",
    "# -------------------------------------------\n",
    "_, _, r_value, _, _ = stats.linregress(x, y2)\n",
    "r2_2 = r_value**2\n",
    "mse = mean_squared_error(x, y2)\n",
    "rmse_2 = np.sqrt(mse)  \n",
    "# -------------------------------------------\n",
    "\n",
    "\n",
    "print(f\"{name}, RFR: {np.round(r2_1, 2)}, {np.round(rmse_1, 2)}; MDS: {np.round(r2_2, 2)}, {np.round(rmse_2, 2)}\")\n",
    "# break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "griffin, manage time range...\n",
      "griffin , RFR: 0.72, 3.62; MDS: 0.03, 14.24\n",
      "Roth_L , RFR: 0.81, 3.31; MDS: 0.74, 3.81\n",
      "Roth_N , RFR: 0.25, 11.23; MDS: 0.0, 40.47\n",
      "Roth_S , RFR: 0.15, 10.68; MDS: 0.05, 65.07\n"
     ]
    }
   ],
   "source": [
    "# for griffin and rothamsted\n",
    "# griffin need to change time range!\n",
    "\n",
    "timestamp_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "\n",
    "out_folder = r\"C:\\workspace\\repositories\\fluxlib\\data\\griffin_roth_synthetic_scenario\\comparison\"\n",
    "create_all_parents(out_folder)\n",
    "out_full_folder = r\"C:\\workspace\\repositories\\fluxlib\\data\\griffin_roth_synthetic_scenario\\comparison_full\"\n",
    "create_all_parents(out_full_folder)\n",
    "\n",
    "mds_flder = r\"C:\\workspace\\repositories\\fluxlib\\data\\griffin_roth_synthetic_scenario\\mds_out\"\n",
    "flx4mds_flder = r\"C:\\workspace\\repositories\\fluxlib\\data\\griffin_roth_synthetic_scenario\\groth4mds\"\n",
    "vld_flder = r\"C:\\workspace\\repositories\\fluxlib\\data\\griffin_roth_synthetic_scenario\\groth4mds_csv_validate\"\n",
    "apl_flder = r\"C:\\workspace\\repositories\\fluxlib\\data\\griffin_roth_synthetic_scenario\\groth4rfr_apply\"\n",
    "\n",
    "mds_paths = list(Path(mds_flder).glob(r\"*.txt\"))\n",
    "mds_time_paths = list(Path(flx4mds_flder).glob(r\"*.txt\"))\n",
    "vld_paths = list(Path(vld_flder).glob(r\"*.csv\"))\n",
    "apl_paths = list(Path(apl_flder).glob(r\"*.csv\"))\n",
    "\n",
    "for count, pm in enumerate(mds_paths):\n",
    "    name = pm.stem[0: -4]\n",
    "    df_app = pd.read_csv(apl_paths[count], index_col = 0)\n",
    "    df_app.index = df_app.index.map(\n",
    "        lambda x: datetime.strptime(str(x), timestamp_format)\n",
    "    )\n",
    "    if count == 0:\n",
    "        print(\"griffin, manage time range...\")\n",
    "        mds_time = pd.read_csv(mds_time_paths[count], delimiter = \"\\t\", skiprows = [1])[[\"Year\", \"DoY\", \"Hour\"]]\n",
    "        split_time = mds_time['Hour'].astype(str).str.split('.', 1, expand = True)\n",
    "        mds_time[\"Hour\"] = split_time[0].astype(int)\n",
    "        mds_time[\"Minute\"] = split_time[1].astype(int) * 6\n",
    "        mds_time[\"time\"] = mds_time[\"Year\"].astype(str) + \"-\" + mds_time[\"DoY\"].astype(str) + \\\n",
    "                           \" \" + mds_time[\"Hour\"].astype(str).str.zfill(2) + \":\" + mds_time[\"Minute\"].astype(str).str.zfill(2)\n",
    "        # print(mds_time)\n",
    "        mds_time[\"time\"] = mds_time[\"time\"].map(\n",
    "            lambda x: datetime.strptime(x, r\"%Y-%j %H:%M\")\n",
    "        )\n",
    "        mds_time = mds_time[\"time\"]\n",
    "        df_app = df_app.loc[mds_time, :]\n",
    "        # print(mds_time)\n",
    "    \n",
    "        mds = pd.read_csv(pm, delimiter = \"\\t\", skiprows = [1]).set_index(mds_time)[[\"NEE_f\"]]\n",
    "        mds = mds.replace(-9999, np.nan)\n",
    "    else:\n",
    "        mds = pd.read_csv(pm, delimiter = \"\\t\", skiprows = [1]).set_index(df_app.index)[[\"NEE_f\"]]\n",
    "        mds = mds.replace(-9999, np.nan)\n",
    "    \n",
    "    rfr = df_app[[\"truth\", \"estimates\"]]\n",
    "    res = pd.concat([rfr, mds], axis = 1)\n",
    "    res.to_csv(Path(out_full_folder).joinpath(f\"{pm.stem[0: -4]}.csv\"))\n",
    "    \n",
    "    \n",
    "    vld = pd.read_csv(vld_paths[count], index_col = 0)\n",
    "    vld.index = vld.index.map(\n",
    "        lambda x: datetime.strptime(str(x), timestamp_format)\n",
    "    )\n",
    "    # print(vld)\n",
    "    extract_vld = res.loc[vld.index]\n",
    "    x = extract_vld.dropna()[\"truth\"]\n",
    "    y1 = extract_vld.dropna()[\"estimates\"]\n",
    "    y2 = extract_vld.dropna()[\"NEE_f\"]\n",
    "    #--------------------------------------------\n",
    "    _, _, r_value, _, _ = stats.linregress(x, y1)\n",
    "    r2_1 = r_value**2\n",
    "    mse = mean_squared_error(x, y1)\n",
    "    rmse_1 = np.sqrt(mse)   \n",
    "    # -------------------------------------------\n",
    "    _, _, r_value, _, _ = stats.linregress(x, y2)\n",
    "    r2_2 = r_value**2\n",
    "    mse = mean_squared_error(x, y2)\n",
    "    rmse_2 = np.sqrt(mse)  \n",
    "    # -------------------------------------------\n",
    "    \n",
    "    extract_vld.to_csv(Path(out_folder).joinpath(f\"{pm.stem[0: -4]}.csv\"))\n",
    "    print(f\"{name}, RFR: {np.round(r2_1, 2)}, {np.round(rmse_1, 2)}; MDS: {np.round(r2_2, 2)}, {np.round(rmse_2, 2)}\")\n",
    "    # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
