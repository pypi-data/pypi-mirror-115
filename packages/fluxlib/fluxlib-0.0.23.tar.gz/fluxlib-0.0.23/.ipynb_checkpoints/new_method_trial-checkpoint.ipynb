{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fluxlib import *\n",
    "from scitbx import *\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load lowcost config for gapfilling\n",
    "cfg = Yaml(\"rfr_gapfill_malaysia_cfg.yaml\").load()\n",
    "drivers = cfg[\"drivers\"]\n",
    "flux = cfg[\"flux\"]\n",
    "rg = cfg[\"rg\"]\n",
    "qc = cfg[\"qc\"]\n",
    "timestamp_format = cfg[\"timestamp_format\"]\n",
    "data_path = Path(cfg[\"source\"])\n",
    "# -------------------------------------------------\n",
    "test_folder = Path(cfg[\"destination\"][\"test\"])\n",
    "create_all_parents(test_folder)\n",
    "# ------------------------------\n",
    "apply_folder = Path(cfg[\"destination\"][\"apply\"])\n",
    "create_all_parents(apply_folder)\n",
    "# ------------------------------\n",
    "flux4mds_folder = Path(cfg[\"destination\"][\"flux4mds\"])\n",
    "create_all_parents(flux4mds_folder)\n",
    "# ------------------------------\n",
    "flux4mds_validation_folder = Path(cfg[\"destination\"][\"flux4mds_validation\"])\n",
    "create_all_parents(flux4mds_validation_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create gaps:\n",
    "def make_gap_pipeline(df, flux):\n",
    "    series = df[flux]\n",
    "    np.random.seed(0)\n",
    "    pointers = np.arange(len(series))\n",
    "    samples = []\n",
    "\n",
    "    # scenario 1:\n",
    "    tgr = 0.25 # total_gap_ratio\n",
    "    window_size = 48 * 30 # long gaps\n",
    "    p = 0.5 * tgr\n",
    "    # print(pointers.shape[0])\n",
    "    samples_lg, pointers = utils.make_gaps(pointers, window_size, p, series)\n",
    "    # print(pointers.shape[0] + len(samples))\n",
    "\n",
    "    window_size = 48 * 7\n",
    "    p = 0.3 * tgr\n",
    "    samples_mg, pointers = utils.make_gaps(pointers, window_size, p, series)\n",
    "\n",
    "    window_size = 48 * 1\n",
    "    p = 0.2 * tgr\n",
    "    samples_sg, pointers = utils.make_gaps(pointers, window_size, p, series)\n",
    "\n",
    "    samples.extend(samples_lg)\n",
    "    samples.extend(samples_mg)\n",
    "    samples.extend(samples_sg)\n",
    "\n",
    "#     # scenario 2:\n",
    "#     tgr = 0.5 # total_gap_ratio\n",
    "#     window_size = 48 * 200\n",
    "#     p = 1 * tgr\n",
    "#     samples_sl, pointers = utils.make_gaps(pointers, window_size, p, series)\n",
    "#     samples.extend(samples_sl)\n",
    "\n",
    "    # print(len(samples) / len(series))\n",
    "    test_idx = samples\n",
    "    train_idx = pointers.tolist()\n",
    "    # pointers.shape[0] + len(samples), len(series)\n",
    "    return train_idx, test_idx\n",
    "# =================================================================================\n",
    "\n",
    "import sys\n",
    "\n",
    "def run_filling(df, flux, rg, train_idx, test_idx):\n",
    "    filler = Filler()\n",
    "    #-------------------------------------------------\n",
    "    # set tags:\n",
    "    df, stat_tags = filler.set_stats(df, flux)\n",
    "    df, season_tag = filler.set_season_tag(df)\n",
    "    df, rg_tag = filler.set_rg_tag(df, rg)\n",
    "    df, doy_year_tag = filler.set_doy_year_tag(df)\n",
    "    #-------------------------------------------------\n",
    "    # prepare and split data for RFR\n",
    "    param_columns = drivers + stat_tags + season_tag + rg_tag + doy_year_tag\n",
    "    # X = df.dropna()[param_columns]\n",
    "    # y = df.dropna()[flux]\n",
    "    X = df[param_columns]\n",
    "    y = df[flux]\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(\n",
    "    #     X, y, \n",
    "    #     test_size=0.33, \n",
    "    #     random_state=42\n",
    "    # )\n",
    "    X = X.interpolate(method = \"pad\")\n",
    "    y = y.interpolate(method = \"pad\")\n",
    "    X_train = X.iloc[train_idx, :]\n",
    "    y_train = y.iloc[train_idx]\n",
    "    X_test = X.iloc[test_idx, :]\n",
    "    y_test =y.iloc[test_idx]\n",
    "\n",
    "    X_apply = df[param_columns].interpolate(method = \"pad\")\n",
    "    y_apply = df[flux]#.interpolate(method = \"pad\")\n",
    "    #--------------------------------------------------\n",
    "    # train and test/apply RFR\n",
    "    regr = filler.train_rfr(X_train, y_train, n_estimators = 100)\n",
    "    # xgbr = filler.train_xgb(X_train, y_train)\n",
    "    result_df, r2, rmse = filler.test_rfr(regr, X_test, y_test)\n",
    "    # result_df, r2, rmse = filler.test_xgb(xgbr, X_test, y_test)\n",
    "    print(f\"{data_path.stem}, {np.round(r2, 4)}, {np.round(rmse, 4)}\")\n",
    "    ## result_df.to_csv(\"fff.csv\")\n",
    "    # applied_df, r2, rmse = filler.test_rfr(regr, X_apply, y_apply)\n",
    "    # print(f\"apply results=> r2:{np.round(r2, 4)}, rmse: {np.round(rmse, 4)}\")\n",
    "    applied_df = filler.test_rfr(regr, X_apply, y_apply, stat = False)\n",
    "    # applied_df = filler.test_rfr(xgbr, X_apply, y_apply, stat = False)\n",
    "    return result_df, applied_df\n",
    "    # sys.exit(0)\n",
    "    \n",
    "# =============================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from skorch import NeuralNetClassifier, NeuralNetRegressor\n",
    "\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size = 1, hidden_size = 4, output_size = 1):\n",
    "        super().__init__()\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_size = input_size,\n",
    "            hidden_size = hidden_size,\n",
    "            num_layers = 3,\n",
    "            batch_first = True,\n",
    "            dropout = 0.2\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 64),\n",
    "            nn.Linear(64, output_size)\n",
    "        )\n",
    "        # self.out = torch.nn.Linear(in_features=hidden_size, out_features=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 一下关于shape的注释只针对单项\n",
    "        # output: [batch_size, time_step, hidden_size]\n",
    "        # h_n: [num_layers,batch_size, hidden_size] # 虽然LSTM的batch_first为True,但是h_n/c_n的第一维还是num_layers\n",
    "        # c_n: 同h_n\n",
    "        output, (h_n, c_n) = self.lstm(x)\n",
    "        # print(output.size())\n",
    "        # output_in_last_timestep=output[:,-1,:] # 也是可以的\n",
    "        output_in_last_timestep = h_n[-1, :, :]\n",
    "        # print(output_in_last_timestep.equal(output[:,-1,:])) #ture\n",
    "        # x = self.out(output_in_last_timestep)\n",
    "        x = self.fc(output_in_last_timestep)\n",
    "        return x\n",
    "\n",
    "net = NeuralNetRegressor(\n",
    "    LSTM,\n",
    "    max_epochs=10,\n",
    "    lr=0.1,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    "    batch_size = 512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1048: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m0.0197\u001b[0m        \u001b[32m0.0021\u001b[0m  1.0946\n",
      "      2        \u001b[36m0.0043\u001b[0m        0.0023  1.1998\n",
      "      3        \u001b[36m0.0042\u001b[0m        0.0022  1.0701\n",
      "      4        \u001b[36m0.0041\u001b[0m        0.0021  0.9655\n",
      "      5        \u001b[36m0.0041\u001b[0m        0.0022  0.9445\n",
      "      6        \u001b[36m0.0040\u001b[0m        \u001b[32m0.0020\u001b[0m  0.9814\n",
      "      7        \u001b[36m0.0039\u001b[0m        0.0021  1.0592\n",
      "      8        \u001b[36m0.0039\u001b[0m        0.0021  1.0592\n",
      "      9        \u001b[36m0.0038\u001b[0m        0.0022  1.5042\n",
      "     10        \u001b[36m0.0038\u001b[0m        0.0021  1.3644\n",
      "0.2904731677427226 0.05737191470802653\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# UNDER DEVELOPMENT!!\n",
    "# improve method -> more general\n",
    "#===========================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "loader = Loader(data_path)\n",
    "df_raw = loader.load_lowcost(drivers + flux, timestamp_format)\n",
    "df = df_raw.copy()\n",
    "nan_idx = np.where(np.isnan(df.values))[0]\n",
    "train_idx, test_idx = make_gap_pipeline(df, flux)\n",
    "train_idx = np.setdiff1d(train_idx, nan_idx)\n",
    "test_idx = np.setdiff1d(test_idx, nan_idx)\n",
    "\n",
    "df[\"hour_dif\"] = (df.index - df.index[0]).total_seconds() / 3600\n",
    "lbl = [\"hour_dif\"]\n",
    "\n",
    "X = df[drivers + lbl]\n",
    "y = df[flux]\n",
    "\n",
    "# -------------------\n",
    "# normalize:\n",
    "for col in range(X.shape[1]):\n",
    "    tmp = X.iloc[:, col]\n",
    "    X.iloc[:, col] = (tmp - np.min(tmp)) / (np.max(tmp) - np.min(tmp))\n",
    "y = (y - np.min(y)) / (np.max(y) - np.min(y))\n",
    "# --------------------\n",
    "\n",
    "X_train = X.iloc[train_idx, :]\n",
    "y_train = y.iloc[train_idx]\n",
    "X_test = X.iloc[test_idx, :]\n",
    "y_test =y.iloc[test_idx]\n",
    "\n",
    "# regr = RandomForestRegressor(\n",
    "#     max_depth = 20, \n",
    "#     min_samples_leaf = 3, \n",
    "#     # max_features = 10,\n",
    "#     min_samples_split = 12,\n",
    "#     n_estimators = 500, \n",
    "#     n_jobs = -1, \n",
    "#     random_state = 0\n",
    "# )\n",
    "# regr = xgb.XGBRegressor(\n",
    "#     objective = \"reg:squarederror\", \n",
    "#     random_state = 0,\n",
    "#     max_depth = 4,\n",
    "#     booster = \"dart\",\n",
    "#     eta = 0.3,\n",
    "#     subsample = 1,\n",
    "#     colsample_bytree = 1,\n",
    "#     reg_alpha = 4,\n",
    "#     reg_lambda = 0,\n",
    "#     scale_pos_weight = 3000,\n",
    "# )\n",
    "# regr = GradientBoostingRegressor()\n",
    "# regr = AdaBoostRegressor()\n",
    "# regr = SVR()\n",
    "\n",
    "# regr.fit(X_train, y_train)\n",
    "# predicts = regr.predict(X_test)[:, np.newaxis]\n",
    "\n",
    "net.fit(X_train.values.astype(np.float32)[:, :, np.newaxis], y_train.values.astype(np.float32))\n",
    "predicts = net.predict_proba(X_test.values.astype(np.float32)[:, :, np.newaxis])\n",
    "\n",
    "df = pd.DataFrame(np.concatenate([y_test, predicts], axis = 1), columns = [\"truth\", \"estimates\"])\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df.dropna()[\"truth\"], df.dropna()[\"estimates\"])\n",
    "r2 = r_value**2\n",
    "mse = mean_squared_error(predicts, y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "print(r2, rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
